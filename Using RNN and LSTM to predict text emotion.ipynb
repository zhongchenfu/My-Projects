{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Using RNN and LSTM to predict text emotion\n",
    "## Abstract\n",
    "\n",
    "This script implements a sentiment analysis pipeline using PyTorch and TorchText to process and classify the IMDB movie review dataset.     It includes preprocessing with Spacy tokenizer and GloVe embeddings, and defines RNN and LSTM neural network models for training.     The models are optimized using Adam and evaluated across multiple epochs to demonstrate effectiveness in predicting sentiments from text reviews.\n",
    "\n",
    "**My project consists of the following three processes：**\n",
    "- Data Handling and Preprocessing\n",
    "- Neural Network Implementation\n",
    "- Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling and Preprocessing\n",
    "Utilizes TorchText and Spacy for loading, tokenizing, and preprocessing the IMDB movie review dataset. Sets up vocabularies with GloVe embeddings to facilitate efficient text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:32<00:00, 2.58MB/s]\n",
      ".vector_cache/glove.6B.zip: 862MB [04:13, 3.40MB/s]                                \n",
      "100%|█████████▉| 399999/400000 [00:19<00:00, 20052.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import spacy #用来将文本字符串分割成单独的词汇或标记\n",
    "import torch #专门用来深度学习的库，提供张量的数据类型\n",
    "import torch.nn as nn #用于构建神经网络\n",
    "import torch.optim as optim #提供各种优化算法\n",
    "from torchtext import data #NLP工具包\n",
    "from torchtext.datasets import IMDB #运用了影评数据集\n",
    "from tqdm import tqdm #在循环过程添进度条\n",
    "#这段代码的功能是设置PyTorch的计算设备，以便在进行神经网络训练时选择合适的硬件（GPU或CPU）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) #这里查看用的哪种设备\n",
    "\n",
    "TEXT = data.Field(tokenize='spacy', include_lengths=True, tokenizer_language='en_core_web_sm')\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "# 加载IMDB数据集，创建训练集和测试集以及验证集\n",
    "train_data, test_data = IMDB.splits(TEXT, LABEL) #自带分割方法，默认0.7训练集\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(22))\n",
    "\n",
    "# 进一步设置了如何为文本和标签数据构建词汇表，并且涵盖了使用预训练词向量。（从训练集中提取所有唯一的单词及符号）\n",
    "MAX_VOCAB_SIZE = 25000 #设置最大词汇量：重点关注数据集中频繁出现的单词\n",
    "TEXT.build_vocab(train_data, max_size=MAX_VOCAB_SIZE, vectors='glove.6B.100d') #使用了预训练词向量glove，把每个单词向量化成长度100的向量，帮助模型更好理解单词语义，提高模型处理文本能力\n",
    "LABEL.build_vocab(train_data) #转化label为0.0/1.0 \n",
    "\n",
    "# 创建训练集、验证集和测试集的迭代器，设置设备\n",
    "BATCH_SIZE = 32 #一次迭代批量处理32个数据\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_within_batch=True, #根据文本长度排序（长或短文本之间的联系）\n",
    "    device=device #用上面探测到的设备来处理\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Implementation\n",
    "Defines and trains RNN and LSTM models using PyTorch to analyze sentiment in text data. Incorporates embedding layers, recurrent layers, and fully connected layers to process and classify textual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义RNN模型和LSTM模型\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, inputs, embedding, hidden, outputs):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(inputs, embedding) #嵌入层：将文本的单词映射到高维向量的过程：根据索引input找到对应单词，embedding是每个单词向量化好之后的长度\n",
    "        self.rnn = nn.RNN(embedding, hidden) \n",
    "        self.fc1 = nn.Linear(hidden, hidden // 2)\n",
    "        self.fc2 = nn.Linear(hidden // 2, outputs) #设置了三层：分别是一层RNN（处理序列数据），两层全连接层（将RNN输出进行降维）\n",
    "        self.relu = nn.ReLU(inplace=True) #设置了一个激活函数，提供非线性\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text) #输入文本通过嵌入层转换成嵌入向量\n",
    "        output, hidden = self.rnn(embedded) #RNN处理嵌入向量，输出每个时间步输出和隐藏状态\n",
    "        predictions = self.relu(self.fc1(hidden.squeeze(0))) \n",
    "        predictions = self.fc2(predictions) #隐藏状态去除张量为1的维度，通过全连接层和ReLU激活层生成最终预测\n",
    "        return predictions\n",
    "#如果把 RNN 网络在一个时间步的活动可视化，你会看到有 100 个输入神经元，每个神经元同时接收来自 32 个不同样本的数据。\n",
    "#每个样本的数据是独立处理的，尽管使用的是相同的神经元。\n",
    "#这种结构允许 RNN 能够有效地处理包含多个独立样本的批次数据，这些数据共享相同的网络权重，但各自维护自己的状态信息。\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, inputs, embedding, hidden, outputs):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(inputs, embedding)\n",
    "        self.lstm = nn.LSTM(embedding, hidden) #这里换成了LSTM模型\n",
    "        self.fc1 = nn.Linear(hidden, hidden // 2)\n",
    "        self.fc2 = nn.Linear(hidden // 2, outputs)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "#结构与上面RNN一样\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        predictions = self.relu(self.fc1(hidden[-1]))  # Use the last hidden state\n",
    "        predictions = self.fc2(predictions)\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "Conducts training, validation, and testing across multiple epochs, using Adam optimizer and binary cross-entropy loss. Includes functionality to predict sentiment on new reviews, demonstrating the models' effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25002\n"
     ]
    }
   ],
   "source": [
    "#这部分代码是一个神经网络训练流程，包括初始化模型、定义优化器和损失函数、训练和验证过程，以及准确率计算的实现。\n",
    "# 初始化模型和优化器\n",
    "INPUT = len(TEXT.vocab)\n",
    "print(INPUT)\n",
    "EMBEDDING = 100\n",
    "HIDDEN = 128\n",
    "OUTPUT = 1 #二分类问题，维度为1\n",
    "#以上定义了文本长度、嵌入向量维度、RNN或LSTM隐藏单元数和输出层维度\n",
    "model = RNN(INPUT, EMBEDDING, HIDDEN, OUTPUT)\n",
    "#这里我们先初始化RNN模型进行训练\n",
    "optimizer = optim.Adam(model.parameters) #Adam优化器，是自适应学习率的方法\n",
    "criterion = nn.BCEWithLogitsLoss() #损失函数使用二元交叉熵损失\n",
    "# 将模型和损失函数移至设备\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "\n",
    "# 计算准确率\n",
    "def binary_accuracy(predicts, y):\n",
    "    rounded_predicts = torch.round(torch.sigmoid(predicts)) #把预测值转化为0/1的标量\n",
    "    correct = (rounded_predicts == y).float() #计算预测正确的个数\n",
    "    accuracy = correct.sum() / len(correct) #计算准确率\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# 训练\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    model.train() #将模式设置为训练模式（为了后面的Dropout）\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0 #初始化损失和准确率\n",
    "    for batch in tqdm(iterator, desc=f'Epoch [{epoch + 1}/{EPOCHS}]', delay=0.1): #用tqdm迭代器包装训练数据迭代器，并添加进度条和描述\n",
    "        optimizer.zero_grad() #对于每个批次，清除之前的梯度\n",
    "        predictions = model(batch.text[0]).squeeze(1) \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        accuracy = binary_accuracy(predictions, batch.label)\n",
    "        loss.backward() \n",
    "        optimizer.step() #自动梯度计算并更新模型参数\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_accuracy += accuracy.item() \n",
    "    return epoch_loss / len(iterator), epoch_accuracy / len(iterator)\n",
    "        #最终返回每个训练周期的平均损失和准确率\n",
    "\n",
    "# 验证函数，与训练相比不包含反向传播和参数更新\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    with torch.no_grad(): #这里标明不进行梯度计算\n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.text[0]).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "            accuracy = binary_accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_accuracy += accuracy.item()\n",
    "    return epoch_loss / len(iterator), epoch_accuracy / len(iterator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]:   1%|          | 6/547 [00:00<00:18, 29.35it/s]Epoch [1/10]: 100%|██████████| 547/547 [00:17<00:00, 31.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.617 | Train Accuracy: 62.43%\n",
      "\tValidation Loss: 0.674 | Validation Accuracy: 59.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]: 100%|██████████| 547/547 [00:19<00:00, 28.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.599 | Train Accuracy: 64.61%\n",
      "\tValidation Loss: 0.681 | Validation Accuracy: 60.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]: 100%|██████████| 547/547 [00:20<00:00, 26.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.590 | Train Accuracy: 65.68%\n",
      "\tValidation Loss: 0.680 | Validation Accuracy: 61.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]: 100%|██████████| 547/547 [00:20<00:00, 26.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.599 | Train Accuracy: 64.41%\n",
      "\tValidation Loss: 0.673 | Validation Accuracy: 61.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]: 100%|██████████| 547/547 [00:14<00:00, 37.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.594 | Train Accuracy: 64.61%\n",
      "\tValidation Loss: 0.689 | Validation Accuracy: 60.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]: 100%|██████████| 547/547 [00:15<00:00, 35.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.600 | Train Accuracy: 64.53%\n",
      "\tValidation Loss: 0.690 | Validation Accuracy: 60.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]: 100%|██████████| 547/547 [00:17<00:00, 30.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.590 | Train Accuracy: 66.37%\n",
      "\tValidation Loss: 0.647 | Validation Accuracy: 63.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/10]: 100%|██████████| 547/547 [00:17<00:00, 30.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.539 | Train Accuracy: 70.83%\n",
      "\tValidation Loss: 0.657 | Validation Accuracy: 63.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]: 100%|██████████| 547/547 [00:16<00:00, 33.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.516 | Train Accuracy: 73.83%\n",
      "\tValidation Loss: 0.618 | Validation Accuracy: 70.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]: 100%|██████████| 547/547 [00:16<00:00, 33.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.477 | Train Accuracy: 77.58%\n",
      "\tValidation Loss: 0.647 | Validation Accuracy: 68.25%\n",
      "\n",
      "Test Loss: 0.715 | Test Acc: 67.27%\n",
      "Proba: 0.6270339488983154\n",
      "Comment: What a fantastic film!\n",
      "Prediction: positive\n",
      "Proba: 0.8357884287834167\n",
      "Comment: I was disappointed by this movie.\n",
      "Prediction: positive\n"
     ]
    }
   ],
   "source": [
    "#接下来是一个完整的训练、验证、测试和使用模型预测的循环过程。\n",
    "EPOCHS = 10 #这里设定进行十轮训练与验证并输出结果\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_accuracy = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_accuracy = evaluate(model, valid_iterator, criterion)\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Accuracy: {train_accuracy * 100:.2f}%')\n",
    "    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation Accuracy: {valid_accuracy * 100:.2f}%')\n",
    "\n",
    "# 测试模型：对模型泛化能力最终检验\n",
    "test_loss, test_accuracy = evaluate(model, test_iterator, criterion)\n",
    "print(f'\\nTest Loss: {test_loss:.3f} | Test Acc: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "# 创建预测模型\n",
    "def predict_sentiment(model, sentence, threshold=0.5):\n",
    "    model.eval() #将模型设置为评估模式（Dropout 不会丢弃任何单元，BatchNorm 会使用整个训练集的统计数据而不是单个批次的）\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)] #对要预测的文本进行分词\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized] #将词汇转换为整数索引\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1) #将索引转换为张量并添加一个维度\n",
    "    prediction = torch.sigmoid(model(tensor)) #预测出结果并处理输出\n",
    "    print(f'Proba: {prediction.item()}')\n",
    "    return 'positive' if prediction.item() > threshold else 'negative'\n",
    "    #打印出模型预测的概率及预测结果\n",
    "\n",
    "# 这里运用了两个实例进行预测\n",
    "positive_comment = \"What a fantastic film!\"\n",
    "negative_comment = \"I was disappointed by this movie.\"\n",
    "print(f'Comment: {positive_comment}\\nPrediction: {predict_sentiment(model, positive_comment)}')\n",
    "print(f'Comment: {negative_comment}\\nPrediction: {predict_sentiment(model, negative_comment)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]: 100%|██████████| 547/547 [00:16<00:00, 33.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.456 | Train Accuracy: 78.30%\n",
      "\tValidation Loss: 0.630 | Validation Accuracy: 70.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]: 100%|██████████| 547/547 [00:18<00:00, 29.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.431 | Train Accuracy: 80.26%\n",
      "\tValidation Loss: 0.628 | Validation Accuracy: 71.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/20]: 100%|██████████| 547/547 [00:18<00:00, 29.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.444 | Train Accuracy: 79.83%\n",
      "\tValidation Loss: 0.636 | Validation Accuracy: 71.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/20]: 100%|██████████| 547/547 [00:21<00:00, 25.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.417 | Train Accuracy: 81.88%\n",
      "\tValidation Loss: 0.621 | Validation Accuracy: 71.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/20]: 100%|██████████| 547/547 [00:22<00:00, 24.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.400 | Train Accuracy: 82.73%\n",
      "\tValidation Loss: 0.621 | Validation Accuracy: 71.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/20]: 100%|██████████| 547/547 [00:20<00:00, 27.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.388 | Train Accuracy: 83.46%\n",
      "\tValidation Loss: 0.622 | Validation Accuracy: 72.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/20]: 100%|██████████| 547/547 [00:19<00:00, 27.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.382 | Train Accuracy: 83.90%\n",
      "\tValidation Loss: 0.616 | Validation Accuracy: 72.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/20]: 100%|██████████| 547/547 [00:17<00:00, 30.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.376 | Train Accuracy: 84.15%\n",
      "\tValidation Loss: 0.630 | Validation Accuracy: 72.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/20]: 100%|██████████| 547/547 [00:17<00:00, 31.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.372 | Train Accuracy: 84.22%\n",
      "\tValidation Loss: 0.620 | Validation Accuracy: 72.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/20]: 100%|██████████| 547/547 [00:19<00:00, 28.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.363 | Train Accuracy: 84.56%\n",
      "\tValidation Loss: 0.613 | Validation Accuracy: 72.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/20]: 100%|██████████| 547/547 [00:18<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.365 | Train Accuracy: 84.31%\n",
      "\tValidation Loss: 0.627 | Validation Accuracy: 72.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/20]: 100%|██████████| 547/547 [00:18<00:00, 29.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.378 | Train Accuracy: 84.30%\n",
      "\tValidation Loss: 0.604 | Validation Accuracy: 73.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/20]: 100%|██████████| 547/547 [00:19<00:00, 28.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.361 | Train Accuracy: 85.01%\n",
      "\tValidation Loss: 0.607 | Validation Accuracy: 72.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/20]: 100%|██████████| 547/547 [00:19<00:00, 28.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.349 | Train Accuracy: 85.45%\n",
      "\tValidation Loss: 0.615 | Validation Accuracy: 72.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/20]: 100%|██████████| 547/547 [00:22<00:00, 24.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.342 | Train Accuracy: 85.62%\n",
      "\tValidation Loss: 0.613 | Validation Accuracy: 73.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/20]: 100%|██████████| 547/547 [00:21<00:00, 25.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.345 | Train Accuracy: 85.71%\n",
      "\tValidation Loss: 0.612 | Validation Accuracy: 73.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/20]: 100%|██████████| 547/547 [00:22<00:00, 23.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.340 | Train Accuracy: 85.89%\n",
      "\tValidation Loss: 0.605 | Validation Accuracy: 73.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/20]: 100%|██████████| 547/547 [00:18<00:00, 29.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.334 | Train Accuracy: 85.81%\n",
      "\tValidation Loss: 0.618 | Validation Accuracy: 73.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/20]: 100%|██████████| 547/547 [00:17<00:00, 31.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.326 | Train Accuracy: 86.43%\n",
      "\tValidation Loss: 0.611 | Validation Accuracy: 73.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/20]: 100%|██████████| 547/547 [00:18<00:00, 28.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.323 | Train Accuracy: 86.77%\n",
      "\tValidation Loss: 0.614 | Validation Accuracy: 73.95%\n",
      "\n",
      "Test Loss: 0.650 | Test Acc: 72.81%\n",
      "Proba: 0.4937834143638611\n",
      "Comment: What a fantastic film!\n",
      "Prediction: negative\n",
      "Proba: 0.40905529260635376\n",
      "Comment: I was disappointed by this movie.\n",
      "Prediction: negative\n"
     ]
    }
   ],
   "source": [
    "#由于以上RNN模型预测结果不理想，对模型进行了调整，是模型更复杂\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, inputs, embedding, hidden, outputs, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(inputs, embedding)\n",
    "        self.rnn = nn.RNN(embedding, hidden, num_layers=2, bidirectional=True, dropout=dropout) #添加了双向和多层RNN\n",
    "        self.fc1 = nn.Linear(hidden * 2, hidden // 2)\n",
    "        self.fc2 = nn.Linear(hidden // 2, outputs)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(dropout) #加入了Dropout，防止模型过拟合\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        hidden = hidden.view(hidden.size(1), -1)  # Flatten the hidden state\n",
    "        predictions = self.relu(self.fc1(self.dropout(hidden)))\n",
    "        predictions = self.fc2(predictions)\n",
    "        return predictions\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001) #将优化器的学习率设置成0.0001\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# 将模型和损失函数移至设备\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# 训练模型\n",
    "EPOCHS = 20 #改为了20个训练周期（epochs）\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_accuracy = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_accuracy = evaluate(model, valid_iterator, criterion)\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Accuracy: {train_accuracy * 100:.2f}%')\n",
    "    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation Accuracy: {valid_accuracy * 100:.2f}%')\n",
    "\n",
    "# 测试模型\n",
    "test_loss, test_accuracy = evaluate(model, test_iterator, criterion)\n",
    "print(f'\\nTest Loss: {test_loss:.3f} | Test Acc: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "# 使用模型进行预测\n",
    "def predict_sentiment(model, sentence, threshold=0.5):\n",
    "    model.eval()\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    print(f'Proba: {prediction.item()}')\n",
    "    return 'positive' if prediction.item() > threshold else 'negative'\n",
    "\n",
    "\n",
    "# 示例预测\n",
    "positive_comment = \"What a fantastic film!\"\n",
    "negative_comment = \"I was disappointed by this movie.\"\n",
    "print(f'Comment: {positive_comment}\\nPrediction: {predict_sentiment(model, positive_comment)}')\n",
    "print(f'Comment: {negative_comment}\\nPrediction: {predict_sentiment(model, negative_comment)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]:   0%|          | 2/547 [00:00<00:42, 12.75it/s]Epoch [1/20]: 100%|██████████| 547/547 [00:20<00:00, 26.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.680 | Train Accuracy: 55.98%\n",
      "\tValidation Loss: 0.668 | Validation Accuracy: 59.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]: 100%|██████████| 547/547 [00:21<00:00, 25.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.682 | Train Accuracy: 54.64%\n",
      "\tValidation Loss: 0.683 | Validation Accuracy: 60.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/20]: 100%|██████████| 547/547 [00:21<00:00, 25.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.518 | Train Accuracy: 75.09%\n",
      "\tValidation Loss: 0.409 | Validation Accuracy: 82.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/20]: 100%|██████████| 547/547 [00:22<00:00, 24.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.292 | Train Accuracy: 88.11%\n",
      "\tValidation Loss: 0.323 | Validation Accuracy: 86.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/20]: 100%|██████████| 547/547 [00:23<00:00, 23.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.193 | Train Accuracy: 92.88%\n",
      "\tValidation Loss: 0.300 | Validation Accuracy: 88.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/20]: 100%|██████████| 547/547 [00:21<00:00, 25.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.123 | Train Accuracy: 96.01%\n",
      "\tValidation Loss: 0.328 | Validation Accuracy: 88.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/20]: 100%|██████████| 547/547 [00:19<00:00, 27.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.076 | Train Accuracy: 97.76%\n",
      "\tValidation Loss: 0.371 | Validation Accuracy: 88.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/20]: 100%|██████████| 547/547 [00:17<00:00, 31.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.045 | Train Accuracy: 98.95%\n",
      "\tValidation Loss: 0.464 | Validation Accuracy: 88.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/20]: 100%|██████████| 547/547 [00:18<00:00, 29.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.030 | Train Accuracy: 99.30%\n",
      "\tValidation Loss: 0.490 | Validation Accuracy: 88.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/20]: 100%|██████████| 547/547 [00:17<00:00, 30.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.022 | Train Accuracy: 99.47%\n",
      "\tValidation Loss: 0.494 | Validation Accuracy: 88.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/20]: 100%|██████████| 547/547 [00:17<00:00, 30.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.016 | Train Accuracy: 99.69%\n",
      "\tValidation Loss: 0.576 | Validation Accuracy: 88.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/20]: 100%|██████████| 547/547 [00:17<00:00, 30.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.017 | Train Accuracy: 99.59%\n",
      "\tValidation Loss: 0.591 | Validation Accuracy: 88.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/20]: 100%|██████████| 547/547 [00:16<00:00, 33.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.013 | Train Accuracy: 99.78%\n",
      "\tValidation Loss: 0.616 | Validation Accuracy: 88.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/20]: 100%|██████████| 547/547 [00:19<00:00, 27.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.019 | Train Accuracy: 99.42%\n",
      "\tValidation Loss: 0.568 | Validation Accuracy: 88.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/20]: 100%|██████████| 547/547 [00:19<00:00, 28.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.010 | Train Accuracy: 99.77%\n",
      "\tValidation Loss: 0.621 | Validation Accuracy: 88.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/20]: 100%|██████████| 547/547 [00:17<00:00, 30.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.006 | Train Accuracy: 99.91%\n",
      "\tValidation Loss: 0.607 | Validation Accuracy: 88.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/20]: 100%|██████████| 547/547 [00:19<00:00, 28.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.011 | Train Accuracy: 99.69%\n",
      "\tValidation Loss: 0.662 | Validation Accuracy: 87.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/20]: 100%|██████████| 547/547 [00:19<00:00, 27.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.008 | Train Accuracy: 99.80%\n",
      "\tValidation Loss: 0.649 | Validation Accuracy: 88.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/20]: 100%|██████████| 547/547 [00:17<00:00, 31.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.007 | Train Accuracy: 99.85%\n",
      "\tValidation Loss: 0.676 | Validation Accuracy: 88.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/20]: 100%|██████████| 547/547 [00:19<00:00, 28.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.002 | Train Accuracy: 99.98%\n",
      "\tValidation Loss: 0.691 | Validation Accuracy: 88.37%\n",
      "\n",
      "Test Loss: 0.837 | Test Acc: 86.17%\n",
      "Proba: 0.9982360601425171\n",
      "Comment: What a fantastic film!\n",
      "Prediction: positive\n",
      "Proba: 0.00921712163835764\n",
      "Comment: I was disappointed by this movie.\n",
      "Prediction: negative\n"
     ]
    }
   ],
   "source": [
    "#这里我们使用LSTM模型进行训练\n",
    "model = LSTM(INPUT, EMBEDDING, HIDDEN, OUTPUT)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# 将模型和损失函数移至设备\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "EPOCHS = 20 #进行20个训练周期\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_accuracy = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_accuracy = evaluate(model, valid_iterator, criterion)\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Accuracy: {train_accuracy * 100:.2f}%')\n",
    "    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation Accuracy: {valid_accuracy * 100:.2f}%')\n",
    "\n",
    "# 测试模型\n",
    "test_loss, test_accuracy = evaluate(model, test_iterator, criterion)\n",
    "print(f'\\nTest Loss: {test_loss:.3f} | Test Acc: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "# 使用模型进行预测\n",
    "def predict_sentiment(model, sentence, threshold=0.5):\n",
    "    model.eval()\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    print(f'Proba: {prediction.item()}')\n",
    "    return 'positive' if prediction.item() > threshold else 'negative'\n",
    "\n",
    "\n",
    "# 示例预测\n",
    "positive_comment = \"What a fantastic film!\"\n",
    "negative_comment = \"I was disappointed by this movie.\"\n",
    "print(f'Comment: {positive_comment}\\nPrediction: {predict_sentiment(model, positive_comment)}')\n",
    "print(f'Comment: {negative_comment}\\nPrediction: {predict_sentiment(model, negative_comment)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
